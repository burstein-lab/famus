{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47aad25f-2a2a-4705-9ec0-5547fe09da28",
   "metadata": {},
   "source": [
    "# FAMUS: Functional Annotation Method Using Siamese neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811abcbc-2bbc-4d56-88fb-5d82682c0f40",
   "metadata": {},
   "source": [
    "Hello! Thank you for trying FAMUS.   \n",
    "This notebook shows how to use FAMUS to annotate sequences and train custom models.   \n",
    "\n",
    "These examples assume you have downloaded and extracted the models fron Zenodo. If you don't need to use the pre-trained models, you can start with the training section to train a toy model and then use it for the annotation example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1026d0e-3753-4bd6-9289-99b77f9dd07d",
   "metadata": {},
   "source": [
    "## Main scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e03030-8610-484f-af0e-1d0c07c3984e",
   "metadata": {},
   "source": [
    "FAMUS has two main scripts: easy_train and easy_classify.  \n",
    "To classify sequences using pre-existing models, we will only need easy_classify.\n",
    "The models to use for classification are configured in cfg.yaml but can be overriden in the command line.  \n",
    "The two scripts are tolerant to interruptions - if they are stopped before finishing, they will continue from where they left off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c3c957-9700-42f9-8fc9-12b2a9739bad",
   "metadata": {},
   "source": [
    "### easy_classify.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513469a7-3e5d-469d-8a0d-3fce9ef8b66f",
   "metadata": {},
   "source": [
    "Used to label input sequences based on existing database models installed in `./models/`.  \n",
    "Will continue interrupted runs if the input and output are the same as the interrupted run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4155b5c1-ae89-4f44-96da-1e0e3afe26c9",
   "metadata": {},
   "source": [
    "**Note:** depending on the number of CPU cores, the example may take a while to run. After downloading the models, it is recommended to run `python3 -m convert_sdf` once to convert the training data from JSON to pickle binaries which makes classification faster. Otherwise, remove the `--load_sdf_from_pickle` flag from easy_classify.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c68e408-c31e-4cd3-a7c9-37d1c0e511be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m convert_sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33a76cd-661a-415c-b30c-7ff068884728",
   "metadata": {},
   "source": [
    "Command line arguments for easy_classify (unused arguments will be read from cfg.yaml):\n",
    "- input_fasta_file_path - the path of the sequeces for classification. (required)\n",
    "- output_dir - the directory to save the results to. (required)\n",
    "- n_processes - number of cpu cores to use.\n",
    "- device - cpu/cuda - in HPC environments with multiple CPU cores, there isn't a real difference.\n",
    "- chunksize - how many sequences to classify per iteration. Decrease if GPU RAM becomes an issue (default is 20,000).\n",
    "- models - space-separated list of model names to use. \n",
    "- models_type - full/light - type of model to use (light is slightly less accurate but significantly faster).\n",
    "- load_sdf_from_pickle - loads training data from pickle instead of json. Only usable after running `python -m convert_sdf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fcfc25-07b3-48d0-87c7-abd7709f8d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m easy_classify --input_fasta_file_path examples/example_for_classification.fasta --output_dir examples/classification_example_results/ --device cpu --n_processes 32 --models kegg interpro --model_type light --load_sdf_from_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91def7d4-6233-4047-8f1e-9ccd79ff38ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head examples/classification_example_results/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5fd508-f6df-4ee9-a334-73102e4ec69d",
   "metadata": {},
   "source": [
    "### easy_train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dbe115-dd7f-49df-bdbb-3475ff377808",
   "metadata": {},
   "source": [
    "Used to create your own models.  \n",
    "Will continue interrupted runs if the input directory/model name is the same, **but** the input fasta directory, unknown sequence fasta, number of epochs, batch size and model type must also be the same or an error will be raised.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a34fd7-968b-4405-a18f-6b9c2a07145f",
   "metadata": {},
   "source": [
    "Command line arguments for easy_train (unused arguments will be read from cfg.yaml):\n",
    "- input_fasta_dir_path - the path of the directory holding fasta files where each file defines a protein family (required). **Note:** every file name **must** end in .fasta, and files must not be named unknown.fasta (since unknown is reserved for unknown sequences)\n",
    "- model_type - full/light. The type of model to create - full models take longer to train and classify but are slightly more accurate.\n",
    "- model_name - optional name for the model that will be used to refer to it in easy_classify. If not specified, the input directory base name will be used.\n",
    "- unknown_sequences_fasta_path - fasta file with sequences of unknown function as negative examples for the model. Optional but recommended.\n",
    "- n_processes - number of CPU cores to use.\n",
    "- num_epochs - number of epochs to train the model for.\n",
    "- batch_size - training batch size.\n",
    "- stop_before_training - calling easy_train with --stop_before_training will exit before starting to train the model (useful for things like preprocessing in a high-CPU environment and them training the model in a different environment with CUDA).\n",
    "- device - cpu/cuda.\n",
    "- chunksize - reduce if GPU RAM becomes an issue when calculating threshold using GPU.\n",
    "- save_every - save a checkpoint of the model's state every \\<save_every> steps. Will load the last checkpoint automatically if the script is restarted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250a68b9-f596-47bd-b428-f8c82b4386c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m easy_train --input_fasta_dir_path examples/example_orthologs/ --model_type light --model_name adar_example --unknown_sequences_fasta_path examples/unknowns.fasta --device cpu --chunksize 1000 --num_epochs 100 --save_every 1000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
